# Set global options
data_dir: "/var/lib/vector"

api:
  enabled: false

sources:
  journald_logs:
    type: journald
  docker_logs:
    type: docker_logs

transforms:
  journald_transform:
    inputs:
    - "journald_logs"
    type: remap
    source: |
      . = {
        "@timestamp": now(),
        "hostname": ._HOSTNAME,
        "unit": ._SYSTEMD_UNIT,
        "pid": ._PID,
        "message": .message,
        "source": "journald"
      }

      .level = if .PRIORITY == 0 {
          "emergency"
      } else if .PRIORITY == 1 {
          "alert"
      } else if .PRIORITY == 2 {
          "critical"
      } else if .PRIORITY == 3 {
          "error"
      } else if .PRIORITY == 4 {
          "warning"
      } else if .PRIORITY == 5 {
          "notice"
      } else if .PRIORITY == 6 {
          "info"
      } else if .PRIORITY == 7 {
          "debug"
      } else {
          "info"
      }


  docker_transform:
    inputs:
    - "docker_logs"
    type: remap
    source: |
      . = {
        "@timestamp": now(),
        "container_id": .container_id,
        "container_name": .container_name,
        "image": .image,
        "source": "docker",
        "original_message": .message  
      }

      parsed, err = parse_json(.original_message)
      if err == null {
        .log_parsed = parsed
        .log_type = "json"
        del(.original_message)
        del(.message)
      } else {
        .message = .original_message
        .log_type = "plain"
        del(.original_message)
      }

      # Traefik
      if .container_name == "traefik"  {
        .level = .log_parsed.level
        .http_method = .log_parsed.RequestMethod
        .http_status, err = to_int(.log_parsed.OriginStatus)
        .http_path = .log_parsed.RequestPath
        .http_host = .log_parsed.RequestHost
        .client_ip = .log_parsed.ClientHost
        .response_time_ms = to_float(.log_parsed.Duration) / 1000000.0
        .http_scheme = .log_parsed.RequestScheme
        .full_url, err = .http_scheme + "://" + .http_host + .http_path
      }

      # Elasticsearch
      if starts_with(string!(.container_name), "es") {
        .level = downcase(string!(.log_parsed."log.level"))
        .cluster_name = .log_parsed."elasticsearch.cluster.name"
        .node_name = .log_parsed."elasticsearch.node.name"
      }
  

sinks:
  journald_sink:
    inputs:
    - "journald_transform"
    type: "elasticsearch"
    endpoints:
    - "https://es01:9200"
    bulk:
      action: index
      index: "vector-journald-%Y-%m-%d"
    tls:
      ca_file: /var/lib/vector/certs/ca.crt
    auth:
      strategy: basic
      user: kovalev.v
      password: "password"
    api_version: auto
    compression: gzip
    batch:
      max_bytes: 1000000
      timeout_secs: 5

  docker_sink:
    inputs:
    - "docker_transform"
    type: "elasticsearch"
    endpoints:
    - "https://es01:9200"
    bulk:
      action: index
      index: "vector-docker-v4-%Y-%m-%d"
    tls:
      ca_file: /var/lib/vector/certs/ca.crt
    auth:
      strategy: basic
      user: kovalev.v
      password: "password"
    api_version: auto
    pipeline: vector-mask-ip
    compression: gzip
    batch:
      max_bytes: 1000000
      timeout_secs: 5
